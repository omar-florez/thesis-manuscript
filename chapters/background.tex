%=============================================================================
% Background
% Copyright (c) 2018. Lester James V. Miranda
%
% This file is part of thesis-manuscript.
%
% thesis-mansucript is free software: you can redistribute it and/or modify
% it under the terms of the GNU General Public License as published by
% the Free Software Foundation, either version 3 of the License, or
% (at your option) any later version.
%
% thesis-manuscript is distributed in the hope that it will be useful,
% but WITHOUT ANY WARRANTY; without even the implied warranty of
% MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
% GNU General Public License for more details.
%
% You should have received a copy of the GNU General Public License
% along with thesis-manuscript.  If not, see <http://www.gnu.org/licenses/>.
%
% Created by: Lester James V. Miranda <ljvmiranda@gmail.com>
%=============================================================================

\chapter{Background of the Study}
\label{BackgroundChapter}

\par In this chapter, we begin by looking into the problem of protein
function prediction in the lens of how protein data is usually represented
(Sec. \ref{ProteinFunctionPrediction}). Then, armed with the knowledge that
proteins can perform multiple functions at once, we will frame the protein
function prediction problem as a multilabel classification task (Sec.
\ref{MultilabelClassification}). We will argue that learning new
representations from data is vital to accomplish this task (Sec.
\ref{FeatureExtraction}), and at the same time introduce the autoencoder
neural network as basis for our methods. We then examine
previous works that have tackled this problem with a similar approach (Sec.
\ref{LiteratureReview}) and finally, express our research motivation
(Sec. \ref{Motivation}) and formulate research questions and hypotheses
throughout this work.


\section{Protein Data Representation}
\label{ProteinFunctionPrediction}

Approaching the protein function prediction problem requires an
understanding of how protein data is often represented. We always
describe proteins in two ways: first by their (1) \textit{features} or
characteristics, and then by their (2) \textit{labels} or functional
categories.

\subsection{Protein features from high-throughput methods}

\par High-throughput sequencing techniques ushered in the emergence of
genomic big data (\cite{reuter2015high}). Scientists conducted various
experiments (e.g. DNA microarray, phylogenetic trees, etc.) to profile
protein sequences, resulting to huge amounts of structured data available for
use. These datasets facilitated protein function prediction, be it through
biochemical or computational means (\cite{eisenberg2000protein,
marcotte1999combined}). Similarly, we will be using two protein benchmarks, Yeast and
Genbase, derived from these experiments.

\par We define a \textit{protein feature set} as a matrix $\mathbf{X}$ where
each row and column is represented as a protein sample $i=1\dots N$ and a
specific measurement $j=1\dots d$ respectively. Both Yeast and Genbase
datasets were formed from microarray gene expression data, with the former
containing phylogenetic profiles as additional information. Succintly, the
raw feature set is defined as $\mathbf{X} \in \mathbb{R}^{N \times d}$ where $N$
is the number of protein samples and $d$ is the dimension or number of
attributes.

\par It is vital to spend some time emphasizing that noise is intrinsic to
high-throughput data (\cite{hong2013estimating}). A DNA microarray, for
example, is formed by probing unique regions of a gene in order to detect
expressions present in the tissue. Probing is sometimes conducted
heterogeneously, for ``different parts of the body, different [organisms], or
different phases of the cellular cycle'' (\cite{nguyen2009noise}). Each step
has the potential to introduce noise that may be detrimental to our task. To
a greater extent, extracting features from noisy data can compound its effect
and damage our classification model. Later on, we will discuss the denoising
autoencoder as a way to reduce the effect of noise from our raw features; but
first, let's look into what these features correspond to\textemdash a
protein's function.

\subsection{Protein functions}

\par Proteins perform a variety of functions to maintain our survival. They
can be seen in almost every facet of our biological processes: cell
reproduction, signalling, metabolism, and etc. By design, a singular protein
can perform multiple functions at once. This means that there is a
one-to-many relationship between protein samples and its function/s. A good
example is the YAL041W protein found in \textit{S. cerevisiae} or baker's
yeast (\cite{elisseeff2001kernel}) in Figure \ref{demo:yeast_go}. 


\begin{figure}[!h]
  \centering
  \includegraphics[width=0.65\textwidth]{ch01/demo_ontology}
  \caption{Functional categories of protein YAL041W in \textit{S. cerevisiae}}
  \label{demo:yeast_go}
\end{figure}

\noindent YAL041W is associated with multiple functional categories: cell growth,
organization, communication, and viral detection. To an extent, these
categories are not related to one another yet they are wilfully performed by
a single protein.

\par We define a set of protein functions or \textit{labels} as a binary
matrix $\mathbf{Y}$ where each row $i=1 \dots N$ is a protein sample, and
each column $j=1 \dots q$ is a protein function (designated as $\lambda$).
The size of $q$ depends on the number of possible labels in the dataset. In
addition, a protein labelset (a row vector) $\mathbf{y}_n$ is encoded as a
one-hot vector of size $q$. Say we're given a protein sample $n$ that performs
functions $\lambda_1, \lambda_4,$ and $\lambda_5$ in a set that only has
five functional categories, $q=5$, then we express its labelset as:

\[
    \mathbf{y}_n = \left[\begin{matrix}
        1 & 0 & 0 & 1 & 1
    \end{matrix} \right]
\]

More formally, we represent a set of protein labelsets as $\mathbf{Y} \in
\{0,1\}^{N \times q}$, where each row-vector $\mathbf{y}_n \in \{0,1\}^q$
is a labelset containing $q$ labels $\lambda$. 


\newpage
Together, we have the following definition:

\begin{definition}{}
A protein dataset $\mathcal{D}$ consists of $N$ pairs of feature and label
vectors $\{(\mathbf{x}_i, \mathbf{y}_i)\}_{i=1}^{N}$ where $\mathbf{x}_i \in
\mathbb{R}^d$ and $\mathbf{y}_i \in \{0,1\}^q$. In matrix-form, $\mathcal{D}$
consists of feature and label matrices, $\mathcal{D} = \langle \mathbf{X},
\mathbf{Y} \rangle$ where $\mathbf{X} \in \mathbb{R}^{N \times d}$ and
$\mathbf{Y} \in \{0,1\}^{N \times q}$.
\end{definition}

\par We will use this definition as we formulate the protein function
prediction problem as a multilabel classification task.


\section[Protein Function Prediction as a Multilabel Classification Task]
{Protein Function Prediction as a Multilabel\\Classification  (MLC) Task}
\label{MultilabelClassification}

\par Classification is one of the most common tasks in machine learning
(\cite{herrera2016multilabel}). Given input features $\mathbf{X}$ and its
label $y$, the goal is to find a mapping function $\mathcal{H}: \mathbf{X}
\rightarrow y$ that can accurately associate each set of attributes to its
particular label. For prediction, we then use the mapping function as
$\mathcal{H}: \mathbf{X} \rightarrow \widehat{y}$. A good example is image
classification, where given an image, the classifier must be able to
distinguish what particular object (or animal) it belongs to.

\begin{figure}[!h]
  \centering
  \includegraphics[width=0.70\textwidth]{ch01/demo_tradclass}
  \caption[Demonstration of traditional classification in images]
  {Demonstration of traditional classification in images.\\Cat photo
  from ImageNet (\cite{russakovsky2015imagenet})}
  \label{demo:traditional}
\end{figure}

\par However, we are well aware that proteins can perform multiple functions
at once, and that the traditional definition of classification does not apply
to our given task. Instead, we aim to discriminate between \textit{multiple
labels} and associate them to the feature set. An apt counterpart to image
classification is scene classification (\cite{boutell2004learning}), where
multiple objects (or animals) are associated to a given image.

\begin{figure}[!h]
  \centering
  \includegraphics[width=0.95\textwidth]{ch01/demo_multilabel}
  \caption[Demonstration of multilabel classification]
  {Demonstration of multilabel classification.\\Beach photo
  from ImageNet (\cite{russakovsky2015imagenet})}
  \label{demo:multilabel}
\end{figure}

\newpage
\par Protein function prediction behaves similarly to scene classification:
given a protein sample (i.e., the image/scene), we are required to find the
functional categories associated with it (i.e., the objects in the scene).
This task is known as \textit{multilabel classification} (MLC). Notice that
in MLC, for each label $\lambda$, we only have two classes: $0$ (does not
belong to $\lambda$) and $1$ (belongs to $\lambda$). Thus, MLC is akin to
doing binary classification for each label. Formally, we define the multilabel
classification task as:

\begin{definition}{}
Given a dataset $\mathcal{D}$, find a function $\mathcal{H}$ that maps the
feature matrix $\mathbf{X}$ to a set of labels $\mathbf{Y}$, i.e.,
$\mathcal{H}: \mathbf{X} \rightarrow \mathbf{Y}$. For any unseen instance
$\mathbf{x} \in \mathcal{X}$, where $\mathcal{X} \in \mathbb{R}^d$, we
predict its corresponding label vector $\mathbf{\widehat{y}}$ via
$\mathcal{H}(\mathbf{X}) \subseteq \mathcal{Y}$ where $\mathcal{Y} = \{y_1,
y_2, \dots, y_n, \dots, y_q\}$ and $y_n \in \{0,1\}$\footnote{Adapted from
\cite{zhang2014review}}.
\end{definition}

\par Next, we will discuss a commonly-used approach in solving multilabel
classification problems: binary relevance.

\subsection{Binary relevance in multilabel classification}

\par Binary relevance (BR) decomposes a multilabel problem into a series of
single-label classification tasks (\cite{godbole2004discriminative,
tsoumakas2007multilabel}). The concept is to take any ``off-the-shelf''
classifier $h$ and train it on each label $\lambda$, fitting a total of $q$
classifiers as seen in Figure \ref{demo:binaryrelevance}. Further
modifications to BR include combining labels, or building chains of
classifiers (\cite{read2009classifier}). However, due to BR's conceptual
simplicity and time-complexity\footnote[2]{
    Most problem-transformation techniques have an overhead time-complexity
    depending on the classifier $h$. For Binary relevance, we have $\bigO(q
    \cdot h(N, d))$. At inference, the complexity is $\bigO(q
    \cdot h(d))$. This is relatively faster compared to Classifier Chains
    $\bigO(q \cdot h(N, d + q))$ or Label Ranking $\bigO(q^{2} \cdot h(N, d))$
    (\cite{zhang2014review}).
}, it has been widely used in literature (\cite{zhang2017binary}).

\begin{figure}[!h]
  \centering
  \includegraphics[width=0.65\textwidth]{ch01/demo_binaryrelevance}
  \caption[Binary relevance classification diagram]
  {Binary relevance classification diagram.\\Train $q$ classifiers $h$ for each
  label $\lambda$}
  \label{demo:binaryrelevance}
\end{figure}

\par BR falls under one of the two main approaches in classifying multilabel data:
problem transformation and algorithm adaptation. The former, where BR
belongs, transforms the multilabel problem into separate single-label binary
classification tasks while the latter adapts a classifier to directly handle
multilabel data (\cite{tsoumakas2007multilabel}).

\par We focus on BR for it is easier to treat the classifier as a separate
module from the feature extractor, and it is a simple yet effective method
for multilabel classification (\cite{luaces2012binary}). With BR, a
classifier can be decoupled from a feature extractor, enabling the former to
be tested on variants of the latter. Another reason is that the literature on
problem transformation techniques is extensive enough to enable benchmarking
of different multilabel classifiers in the future (\cite{zhang2014review,
madjarov2012extensive}).

\par This research will concentrate on finding good representations for the
BR classifier to solve the problem of protein function prediction. The
process of obtaining new features from raw data is called \textit{feature
extraction} and is one of the core ideas in this work. Even if a BR
classifier can stand on its own, we hypothesize that higher performance can
be achieved with the extracted features than the raw data itself.

\section{Extracting Features for better Data Representation}
\label{FeatureExtraction}

\par One of the core ideas in this work is feature extraction\footnote{
  Feature extraction has been referred to in various ways in literature:
  feature learning, representation learning, manifold learning, etc. We will
  use the term ``feature extraction'' in this work.
}
\textemdash where new features are derived from raw attributes for better
data representation, and consequently, better classification. The success of
machine learning algorithms depends on data representations, for it can
entangle manifolds or explanatory factors of variation behind the data
(\cite{bengio2013representation}). 

\par More formally, we want to learn a mapping $\phi$ such that $\phi:
\mathbf{X} \rightarrow \mathbf{X}^{\prime}$, where $\mathbf{X}^{\prime}$
represents the extracted features useful to a classifier $\mathcal{H}$. We
hypothesize that using $\mathbf{X}^{\prime}$ should provide better
classification (perhaps measured in accuracy, F-score, etc.) than just using
the raw attributes $\mathbf{X}$. The proceeding section will give a
simple demonstration using the XOR gate to illustrate this idea.

\subsection{A simple demonstration using the XOR gate}

\par Creating new features can be best illustrated with the XOR gate. The
goal is to separate binary 0's and 1's of the output. We take two
inputs $\mathbf{x} = \langle x_{1}$, $x_{2} \rangle, x_1, x_2 \in \{0,1\}$ as
features and its output $y_{i} \in \{0,1\}$ as the label. With $N=4$ samples
representing all possible bit-combinations, a dataset
$\mathcal{D}=\{(\mathbf{x}_{i}, y_{i})\}_{i=1}^{4}$ can be constructed as:

\[
    \mathcal{D} = \{(0,0,0), (0,1,1), (1,0,1), (1,1,0)\}
\]

Assuming we only have access to a linear classifier, the feature-space shown
in Figure \ref{demo:xor} (\textit{left}) proves that classifying the samples
is difficult due to its linear inseparability\textemdash that is, drawing a
single line to perfectly separate the X's and O's is impossible.
However, if a new feature-space $\mathbf{x}^{\prime}$ is engineered in such a
way that $\mathbf{x}^{\prime} = \langle {x}^{\prime}_{1}, {x}^{\prime}_2 \rangle$ where 
$x^{\prime}_{1} = \text{AND}(\bar{x}_{1}, x_{2})$ and $x^{\prime}_{2}
= \text{AND}(x_{1}, \bar{x}_{2})$, then it is possible to transform $\mathcal{D}$
into dataset $\mathcal{D}^{\prime}=\{(\mathbf{x}^{\prime}_{i}, y_{i})\}_{i=1}^{4}$
where:

\[
    \mathcal{D}^{\prime} = \{(0,0,0), (1,0,1), (0,1,1), (0,0,0)\}
\]

\par It can then be seen from Figure \ref{demo:xor} (\textit{right}) that
$\mathcal{D}^{\prime}$ is now a linearly separable problem. In this
demonstration, it is evident that hand-engineering features, or
\textit{extracting new features} has been helpful. However, with large
datasets, it will be tedious to manually find useful representations from
data. It is much preferable to automate the whole process. In the next
section, we will turn our attention to an effective way of learning $\phi$ in
a parameterized fashion\textemdash the autoencoder neural network.

\begin{figure}[!t]
  \centering
  \includegraphics[width=0.75\textwidth]{ch01/demo_xor}
  \caption[Illustration of feature extraction using the XOR gate]
    {Illustration of feature extraction using the XOR gate. Binary `1's are represented as
    circles while binary `0's as cross-marks.}
  \label{demo:xor}
\end{figure}

\subsection{The autoencoder neural network}

\begin{wrapfigure}{r}{0.5\textwidth}
  \centering
  \includegraphics[width=0.40\textwidth]{ch01/schema_autoencoder}
  \caption[Diagram of the basic autoencoder]{
      Diagram of the basic autoencoder
  }
  \label{schema:autoencoder}
\end{wrapfigure}

\par This research is based on the autoencoder neural network as a framework
for solving the protein function prediction problem. It was first introduced
in 1987 (\cite{lecun1987phd}) and was subsequently studied in the following
years (\cite{bourlard1988auto, hinton1994autoencoders}). The idea is simple
yet powerful, that is, to have a network reconstruct a given input with the
presence of information bottlenecks.

\par There are two key aspects in training autoencoders: (1) information
reconstruction and (2) information bottleneck. The concept is that if an
autoencoder can reconstruct information ``perfectly'', even with constraints
involved, then it has learned the latent structure of the raw data. The
simplest way to constrain an autoencoder is by limiting the number of hidden
nodes $e$ less than the original dimension $d$ of the data. Say for example,
a dataset with $d=100$ dimensions. If we set $e=20$, and the autoencoder was
still able to reconstruct the original data ``perfectly'', then it has
learned a hidden structure from the data expressed in a lesser capacity.

\par In practice, the autoencoder architecture consists of an encoder-decoder
scheme where the encoder function $f_{\theta}$ transforms the original input
$\mathbf{X}$ into a certain representation $\mathbf{h}$ (from $100$ features
to $20$), and the decoder function $g_{\theta^{\prime}}$ converts
$\mathbf{h}$ into an approximation of the original input
$\mathbf{\widehat{X}}$ (where $\mathbf{\widehat{X}} =
g_{\theta^{\prime}}(\mathbf{h}) \approx \mathbf{X}$). We contrive the network
to reconstruct $\mathbf{X}$ by setting the loss function as a comparison of
the original input and its approximation:

\[
    J(\theta) = L(\mathbf{X}, \mathbf{\widehat{X}}) \quad \text{where} \quad
    \mathbf{\widehat{X}} = (g_{\theta^{\prime}} \circ f_{\theta}) (\mathbf{X})
\]

The procedure for training an autoencoder can be seen in Algorithm
\ref{algo:autoenc}.

\input{./inputs/algo_autoenc.tex}

The learned parameters $\theta^{\ast}$ encapsulates the latent structure
discovered by the autoencoder. We can then use this to transform our original
data via the encoder function\textemdash i.e, $ \mathbf{X}^{\prime} =
f_{\theta^{\ast}}(\mathbf{X})$, we treat $f_{\theta^{\ast}}$ as
$\phi$\textemdash and feed the transformation $\mathbf{X}^{\prime}$ into the
multilabel classifier $\mathcal{H}$. We can illustrate this simple model in
Figure \ref{schema:pipeline}. In the next section, we will look into various
works that have attempted to solve the protein function prediction problem
using the pipeline similar to the figure above.

\begin{figure}[!t]
  \centering
  \includegraphics[width=0.85\textwidth]{ch01/schema_pipeline}
  \caption{Simple diagram of the protein function prediction model}
  \label{schema:pipeline}
\end{figure}

\section{Review of Related Literature}
\label{LiteratureReview}

\par There are three major movements that we should consider as we trace the
developments in protein function prediction (PFP) in machine learning: first
is by (1) direct classification, then by (2) dimensionality-reduction, and
lastly by (3) deep feature extraction. Machine learning approaches first
involved feeding raw data into a classifier, then found the need to reduce
the number of features in the dataset, and later on realized the need to
learn suitable representations of protein data for the classifier. This
research falls into the third category, utilizing deep neural networks to
learn representations for a multilabel classifier. But before that, let's
start from the beginning, where raw protein data is being fed directly to a
multilabel classifier.

\paragraph{Direct multilabel classification} The earliest attempt to solve
the protein function prediction problem was done by
\cite{elisseeff2001kernel}. They formulated PFP as a ranking problem (not yet
as a multilabel problem but rather an extension of multiclass
classification), and implemented a variant of the support-vector machine
(SVM) known as Rank-SVM. They tested their technique on \textit{S.
cerevisiae}, giving rise to the now known Yeast dataset. Later on,
\cite{diplaris2005protein} benchmarked various techniques on their own
protein data \textemdash the Genbase dataset. It is noteworthy that
in the conclusion of their work, they expressed their intention to
investigate ``alternative representations of the learning problem,'' which
brought a slew of techniques for multilabel classification.

\par This brought forth the main baseline for multilabel classification, the
Binary Relevance (BR) algorithm
(\cite{godbole2004discriminative,tsoumakas2007multilabel}). These were then
extended into Label Powerset (LP) and Classifier Chains (CC)
(\cite{read2009classifier}), but BR's conceptual ease and ``relative speed''
enabled it to stay. Furthermore, various literature reviews attested BR's
performance, especially when paired with an SVM classifier
(\cite{luaces2012binary, zhang2014review,tsoumakas2017data}). For our
research, we will use the Binary Relevance with SVM (BR-SVM) as the baseline
of our work.

\paragraph{Reducing protein data dimensionality} Although binary relevance
has achieved good traction in protein function prediction, training a
classifier for each label can be time-consuming. Researchers have then
resorted to dimensionality-reduction techniques to reduce the number of
features in a protein\footnote{The Genbase dataset, for instance, has $1186$
attributes} (\cite{wang2009using, wang2013protein, wang2017protein}); they
may not reduce the number of labels to train their classifier upon, but they
can perhaps reduce the time it takes to train one. It is important to note
that these techniques gave a semblance to feature extraction. Reducing
dimensions in a data may be akin to finding a different representation of a
feature space. However, this is still limited primarily due to most
techniques being linear with less capacity (\cite{cunningham2015linear}). In
our work, we will compare against the work of \cite{wang2013protein} that
uses Principal Component Analysis (PCA) as a dimensionality-reduction
technique to a k-nearest neighbors classifier (k-NN). They were able to
reduce a protein dataset with $353$ features into $204$, achieving good
classification performance. We chose this method because it follows a similar
pipeline to Figure \ref{schema:pipeline}, and uses a similar data source
(gene expressions) as our protein benchmark.

\paragraph{Deep feature extraction in protein function prediction} Reducing
dimensions in protein data has helped speed-up and improve classification,
but common approaches such as principal component analysis (PCA) and linear
discriminant analysis (LDA) are linear (\cite{bengio2013representation}),
failing to capture the nonlinearities present in a protein's feature space.
This gave way for researchers to apply deep learning techniques to protein
data\textemdash both for protein sequences
(\cite{bhola2014machine,kulmanov2017deepgo, zou2017protein}) and expressions
(\cite{baldi2001bioinformatics, chicco2014deep}). Later on, we will benchmark
against \cite{chicco2014deep}, who used a deep autoencoder network to extract
features from protein gene expressions. Comparing against this method enables
us to have a baseline, traditional autoencoder implementation to check our
proposed architecture upon.

\newpage
\par As mentioned, this research falls under the last category of deep
feature extraction. This method has been useful in aiding the classifier with
a more separable feature space as we've demonstrated earlier in the XOR
example. In addition, with Binary Relevance, we can decouple the feature
extractor from the multilabel classifier enabling us to test our extraction
method to different types of classifier.


\par However, we argue that extracting features is not enough. It is
important to learn representations that are relevant with respect to the
classifier. In the next section, we will express our research
motivation\textemdash clarifying the meaning of feature relevance\textemdash
and formulate the problem as we proceed to the main body of this work.

\section{Research Motivation}
\label{Motivation}


\subsection{Problem formulation and research hypotheses}

% - Where your research comes in
% - Note on decoupling